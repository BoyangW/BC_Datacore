{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weekly Timeline Alignment for 4 OutcomeTables \n",
    "#### This notebook adds addtional feature goal_num (stage of study) to cleaned version of outcome tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandasql as ps\n",
    "import time \n",
    "import datetime \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cleaned tables \n",
    "df_food = pd.read_csv('Outliers/df_food_outliers.csv') \n",
    "df_pa =  pd.read_csv('Result/MVPA/pa_combined.csv') \n",
    "df_pa_16k = pd.read_csv('Result/MVPA/pa_combined_16k.csv') \n",
    "df_pa_20k = pd.read_csv('Result/MVPA/pa_combined_20k.csv') \n",
    "df_sed =  pd.read_csv('Result/sed_clean.csv') \n",
    "df_user = pd.read_csv('Raw Data/users.csv') \n",
    "df_goal = pd.read_csv('Raw Data/goals.csv') \n",
    "df_demo = pd.read_csv('Result/Demographic.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>upload_time</th>\n",
       "      <th>pa_minute_app</th>\n",
       "      <th>pa_minute_shimmer</th>\n",
       "      <th>MVPA_min</th>\n",
       "      <th>study_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>MVPA_min_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-09-06</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1436</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-09-07</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1436</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1436</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-09-12</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1436</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-09-16</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1436</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id upload_time  pa_minute_app  pa_minute_shimmer  MVPA_min  study_id  \\\n",
       "0        1  2012-09-06           20.0                0.0      20.0      1436   \n",
       "1        1  2012-09-07           20.0                2.0      22.0      1436   \n",
       "2        1  2012-09-10           20.0                0.0      20.0      1436   \n",
       "3        1  2012-09-12           20.0                0.0      20.0      1436   \n",
       "4        1  2012-09-16           20.0                4.0      24.0      1436   \n",
       "\n",
       "   gender  MVPA_min_outlier  \n",
       "0       1                 0  \n",
       "1       1                 0  \n",
       "2       1                 0  \n",
       "3       1                 0  \n",
       "4       1                 0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pa.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all outcome variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unify all time format to month/day/year (mm/dd/yyyy)\n",
    "df_sed['upload_time'] = pd.to_datetime(df_sed.upload_time)\n",
    "df_food['upload_time'] = pd.to_datetime(df_food.upload_time)\n",
    "df_pa['upload_time'] = pd.to_datetime(df_pa.upload_time)\n",
    "df_pa_16k['upload_time'] = pd.to_datetime(df_pa_16k.upload_time)\n",
    "df_pa_20k['upload_time'] = pd.to_datetime(df_pa_20k.upload_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columb of interest (sed)\n",
    "df_sed = df_sed[['study_id','upload_time','sed_total','sed_total_outlier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columb of interest (food)\n",
    "df_food = df_food.drop(['gender'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columb of interest (pa)\n",
    "df_pa = df_pa[['study_id', 'pa_minute_app', 'pa_minute_shimmer','upload_time', 'MVPA_min','MVPA_min_outlier']]\n",
    "df_pa_16k = df_pa_16k[['study_id', 'pa_minute_app', 'pa_minute_shimmer','upload_time', 'MVPA_min','MVPA_min_outlier']]\n",
    "df_pa_20k = df_pa_20k[['study_id', 'pa_minute_app', 'pa_minute_shimmer','upload_time', 'MVPA_min','MVPA_min_outlier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all\n",
    "result = pd.merge(df_sed, df_food, how='outer', on=['study_id', 'upload_time'])\n",
    "result_all = pd.merge(result, df_pa, how='outer', on=['study_id', 'upload_time'])\n",
    "result_16k = pd.merge(result, df_pa_16k, how='outer', on=['study_id', 'upload_time'])\n",
    "result_20k = pd.merge(result, df_pa_20k, how='outer', on=['study_id', 'upload_time'])\n",
    "\n",
    "#fill nah with 999999\n",
    "result_all = result_all.fillna(999999)\n",
    "result_16k = result_16k.fillna(999999)\n",
    "result_20k = result_20k.fillna(999999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Time Alignment (goal key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 212 participants in intervention/follow-up period\n"
     ]
    }
   ],
   "source": [
    "#all participants\n",
    "id_list = []\n",
    "for i in range(df_user.shape[0]):\n",
    "    #extract users' name starting with 'mbc2'\n",
    "    if (df_user['username'][i][0:4] == 'mbc2'):\n",
    "        id_list.append(df_user['user_id'][i])\n",
    "id_list.sort()\n",
    "print('There are', len(id_list), 'participants in intervention/follow-up period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#align goal id with study id\n",
    "df_user= df_user[df_user['user_id'].isin(id_list)]\n",
    "df_goal= df_goal[df_goal['user_id'].isin(id_list)]\n",
    "df_align = df_user[['user_id', 'study_id']]\n",
    "df_goal = pd.merge(df_goal, df_align, how='inner', on=['user_id'])\n",
    "df_goal = df_goal[['study_id','goal_start_date', 'periodname','period_num']]\n",
    "df_goal['period_num'] = df_goal['period_num'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "studyIds = list(set(list(df_goal['study_id'])))\n",
    "goal_start = ['1900-01-01']*len(studyIds)\n",
    "periodname = ['baseline']*len(studyIds)\n",
    "period_num = [0]*len(studyIds)\n",
    "d = {'study_id': studyIds, 'goal_start_date': goal_start, 'periodname': periodname, 'period_num':period_num}\n",
    "df_baseline = pd.DataFrame(data=d)\n",
    "\n",
    "df_goal = df_goal.append(df_baseline)\n",
    "df_goal = df_goal.sort_values(by=['study_id','period_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>goal_start_date</th>\n",
       "      <th>periodname</th>\n",
       "      <th>period_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1383.0</td>\n",
       "      <td>1900-01-01</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1383.0</td>\n",
       "      <td>2012-10-15</td>\n",
       "      <td>intervention</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1383.0</td>\n",
       "      <td>2012-10-29</td>\n",
       "      <td>intervention</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1383.0</td>\n",
       "      <td>2012-11-12</td>\n",
       "      <td>intervention</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1383.0</td>\n",
       "      <td>2012-11-26</td>\n",
       "      <td>intervention</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>7831.0</td>\n",
       "      <td>2014-12-29</td>\n",
       "      <td>followup</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>7831.0</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>maintenance</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2753</th>\n",
       "      <td>7831.0</td>\n",
       "      <td>2015-03-30</td>\n",
       "      <td>followup</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>7831.0</td>\n",
       "      <td>2015-04-06</td>\n",
       "      <td>maintenance</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>7831.0</td>\n",
       "      <td>2015-06-29</td>\n",
       "      <td>followup</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2968 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      study_id goal_start_date    periodname  period_num\n",
       "147     1383.0      1900-01-01      baseline           0\n",
       "156     1383.0      2012-10-15  intervention           1\n",
       "157     1383.0      2012-10-29  intervention           2\n",
       "158     1383.0      2012-11-12  intervention           3\n",
       "159     1383.0      2012-11-26  intervention           4\n",
       "...        ...             ...           ...         ...\n",
       "2751    7831.0      2014-12-29      followup           9\n",
       "2752    7831.0      2015-01-05   maintenance          10\n",
       "2753    7831.0      2015-03-30      followup          11\n",
       "2754    7831.0      2015-04-06   maintenance          12\n",
       "2755    7831.0      2015-06-29      followup          13\n",
       "\n",
       "[2968 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_goal['goal_start_date'] = pd.to_datetime(df_goal.goal_start_date)\n",
    "df_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#align the goal key to upload time (all)\n",
    "\n",
    "periodnumList = []\n",
    "for rows in range(result_all.shape[0]):\n",
    "    df_sub = df_goal[df_goal['study_id'] == result_all['study_id'][rows]]\n",
    "    index = 0\n",
    "    for i in list(df_sub['goal_start_date']):\n",
    "        if (result_all['upload_time'][rows] >= i):\n",
    "            index = index + 1\n",
    "        else:\n",
    "            break\n",
    "    index = index - 1\n",
    "    periodnum = list(df_sub['period_num'])[index]\n",
    "    periodnumList.append(periodnum)\n",
    "\n",
    "result_all['goal'] = periodnumList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#align the goal key to upload time (16k cutoff)\n",
    "\n",
    "periodnumList = []\n",
    "for rows in range(result_16k.shape[0]):\n",
    "    df_sub = df_goal[df_goal['study_id'] == result_16k['study_id'][rows]]\n",
    "    index = 0\n",
    "    for i in list(df_sub['goal_start_date']):\n",
    "        if (result_16k['upload_time'][rows] >= i):\n",
    "            index = index + 1\n",
    "        else:\n",
    "            break\n",
    "    index = index - 1\n",
    "    periodnum = list(df_sub['period_num'])[index]\n",
    "    periodnumList.append(periodnum)\n",
    "\n",
    "result_16k['goal'] = periodnumList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#align the goal key to upload time (20k cutoff)\n",
    "\n",
    "periodnumList = []\n",
    "for rows in range(result_20k.shape[0]):\n",
    "    df_sub = df_goal[df_goal['study_id'] == result_20k['study_id'][rows]]\n",
    "    index = 0\n",
    "    for i in list(df_sub['goal_start_date']):\n",
    "        if (result_20k['upload_time'][rows] >= i):\n",
    "            index = index + 1\n",
    "        else:\n",
    "            break\n",
    "    index = index - 1\n",
    "    periodnum = list(df_sub['period_num'])[index]\n",
    "    periodnumList.append(periodnum)\n",
    "\n",
    "result_20k['goal'] = periodnumList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge demographic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add condition (group)\n",
    "df_condition = df_user[['study_id','cond']]\n",
    "result_all = pd.merge(result_all, df_condition, how='inner', on=['study_id'])\n",
    "result_16k = pd.merge(result_16k, df_condition, how='inner', on=['study_id'])\n",
    "result_20k = pd.merge(result_20k, df_condition, how='inner', on=['study_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge demographic info\n",
    "result_all = pd.merge(result_all, df_demo, how='inner', on=['study_id'])\n",
    "result_16k = pd.merge(result_16k, df_demo, how='inner', on=['study_id'])\n",
    "result_20k = pd.merge(result_20k, df_demo, how='inner', on=['study_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename and reorder\n",
    "renames = ['study_id',\n",
    " 'upload_time',\n",
    " 'sed_min',\n",
    " 'sed_min_outlier',\n",
    " 'calories',\n",
    " 'protein',\n",
    " 'total_fat',\n",
    " 'total_carbohydrate',\n",
    " 'sugars',\n",
    " 'fiber',\n",
    " 'calcium',\n",
    " 'sodium',\n",
    " 'saturated_fatty_acids',\n",
    " 'cholesterol',\n",
    " 'fv_credit',\n",
    " 'calories_outlier',\n",
    " 'fv_outlier',\n",
    " 'fat_outlier',\n",
    " 'pa_min_app',\n",
    " 'pa_min_shimmer',\n",
    " 'pa_min',\n",
    " 'pa_min_outlier',\n",
    " 'goal',\n",
    " 'cond',\n",
    " 'date_of_birth',\n",
    " 'age',\n",
    " 'sex',\n",
    " 'relstatus',\n",
    " 'edlevel',\n",
    " 'income',\n",
    " 'employ',\n",
    " 'race',\n",
    " 'ethnicity']\n",
    "\n",
    "result_all.columns = renames\n",
    "result_16k.columns = renames\n",
    "result_20k.columns = renames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "reoder = ['study_id',\n",
    " 'upload_time',\n",
    " 'goal',\n",
    " 'cond',\n",
    " 'date_of_birth',\n",
    " 'age',\n",
    " 'sex',\n",
    " 'relstatus',\n",
    " 'edlevel',\n",
    " 'income',\n",
    " 'employ',\n",
    " 'race',\n",
    " 'ethnicity',\n",
    " 'sed_min', \n",
    " 'pa_min_app',\n",
    " 'pa_min_shimmer',\n",
    " 'pa_min',\n",
    " 'calories',\n",
    " 'protein',\n",
    " 'total_fat',\n",
    " 'total_carbohydrate',\n",
    " 'sugars',\n",
    " 'fiber',\n",
    " 'calcium',\n",
    " 'sodium',\n",
    " 'saturated_fatty_acids',\n",
    " 'cholesterol',\n",
    " 'fv_credit',\n",
    " 'calories_outlier',\n",
    " 'fv_outlier',\n",
    " 'fat_outlier',\n",
    " 'sed_min_outlier',\n",
    " 'pa_min_outlier']\n",
    "\n",
    "result_all = result_all[reoder]\n",
    "result_16k = result_16k[reoder]\n",
    "result_20k = result_20k[reoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "result_all.to_csv('Result/Final/MBC2_all.csv', index=False)\n",
    "result_16k.to_csv('Result/Final/MBC2_16k_cutoff.csv', index=False)\n",
    "result_20k.to_csv('Result/Final/MBC2_20k_cutoff.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
